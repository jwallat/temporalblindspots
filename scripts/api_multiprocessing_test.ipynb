{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=2, max=60), stop=stop_after_attempt(6))\n",
    "def make_completion_request(model_name, prompt, question):\n",
    "    # start_sequence = \"\\nA:\"\n",
    "    # restart_sequence = \"\\n\\nQ: \"\n",
    "\n",
    "    input = prompt.replace(\"{question}\", question)\n",
    "    # logging.info(f\"input: {input}\")\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=model_name,\n",
    "        prompt=input,\n",
    "        temperature=0,\n",
    "        max_tokens=50,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=[\"\\n\"],\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_davinci_completions(model_name, data, run_name, prompt, batch_size):\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    job_df = {\"q_id\": [], \"question\": [], \"answer\": []}\n",
    "\n",
    "    # print(data.head())\n",
    "    for index in tqdm(range(0, len(data))):\n",
    "        question = data[index]\n",
    "\n",
    "        try:\n",
    "            if index % 50 == 0 and index != 0:\n",
    "                print(\"************\", index)\n",
    "                time.sleep(10)\n",
    "            response = make_completion_request(model_name, prompt, question)\n",
    "\n",
    "            if response.choices[0].text.strip() == \"\":\n",
    "                job_df[\"answer\"].append(\"<no response>\")\n",
    "            else:\n",
    "                job_df[\"answer\"].append(response.choices[0].text.strip())\n",
    "        except Exception as e:\n",
    "            print(\"Could not get response. Here is the exception:\", str(e))\n",
    "            job_df[\"answer\"].append(\"<exception>\")\n",
    "\n",
    "        job_df[\"q_id\"].append(index)\n",
    "        job_df[\"question\"].append(question)\n",
    "        # logging.info(\"Got response: \", response)\n",
    "        # logging.info(\"\\n\\n\\n\")\n",
    "        \n",
    "        final_df = pd.DataFrame(job_df)\n",
    "        final_df.to_csv(f\"{run_name}_predictions.csv\", index=False, sep=\"\\t\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def get_davinci_completions_mp(model_name, data, run_name, prompt, batch_size):\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    job_df = {\"q_id\": [], \"question\": [], \"answer\": []}\n",
    "\n",
    "    # chunk df into batches of size 100\n",
    "    # for each batch, create a new process\n",
    "    \n",
    "\n",
    "    # print(data.head())\n",
    "    for index in tqdm(range(0, len(data))):\n",
    "        question = data[index]\n",
    "\n",
    "        \n",
    "    return final_df\n",
    "\n",
    "def handle_qa_pair(index, question, model_name, prompt, run_name, job_df):\n",
    "    try:\n",
    "        if index % 50 == 0 and index != 0:\n",
    "            print(\"************\", index)\n",
    "            time.sleep(10)\n",
    "        response = make_completion_request(model_name, prompt, question)\n",
    "\n",
    "        if response.choices[0].text.strip() == \"\":\n",
    "            job_df[\"answer\"].append(\"<no response>\")\n",
    "        else:\n",
    "            job_df[\"answer\"].append(response.choices[0].text.strip())\n",
    "    except Exception as e:\n",
    "        print(\"Could not get response. Here is the exception:\", str(e))\n",
    "        job_df[\"answer\"].append(\"<exception>\")\n",
    "\n",
    "    job_df[\"q_id\"].append(index)\n",
    "    job_df[\"question\"].append(question)\n",
    "    # logging.info(\"Got response: \", response)\n",
    "    # logging.info(\"\\n\\n\\n\")\n",
    "    \n",
    "    final_df = pd.DataFrame(job_df)\n",
    "    final_df.to_csv(f\"{run_name}_predictions.csv\", index=False, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset(ds_path):\n",
    "    try:\n",
    "        data = pd.read_csv(ds_path)\n",
    "        data[\"Question\"]\n",
    "    except:\n",
    "        data = pd.read_csv(ds_path, delimiter=\"\\t\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def make_completion_request(model_name, prompt, question, index):\n",
    "    delay = random.randint(100, 1000)\n",
    "    \n",
    "    # Wait for the specified delay\n",
    "    # time.sleep(delay / 1000)\n",
    "    time.sleep(index)\n",
    "\n",
    "    return \"this is an answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair: Handling qa pair:  Handling qa pair: Handling qa pair: Handling qa pair: 1   \n",
      "2 03\n",
      "4\n",
      "\n",
      "\n",
      "Finished job:  0\n",
      "Heres the message:  {'qid': 0, 'question': 'Which two U.S. States had a border dispute that had to be settled by the U.S. Supreme Court in April of 2001?', 'answer': 'this is an answer'}Handling qa pair: \n",
      " 5\n",
      "Finished job:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:01<00:14,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  6\n",
      "Finished job:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:02<00:19,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  7\n",
      "Finished job:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:03<00:21,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  8\n",
      "Finished job:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:04<00:22,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  9\n",
      "Finished job:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:05<00:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  10\n",
      "Finished job:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:07<00:29,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  11\n",
      "Finished job:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:09<00:33,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  12\n",
      "Finished job:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:11<00:34,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  13\n",
      "Finished job:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:13<00:35,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  14\n",
      "Finished job:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:15<00:34,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  15\n",
      "Finished job:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:18<00:39,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  16\n",
      "Finished job:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:21<00:41,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  17\n",
      "Finished job:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:24<00:41,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  18\n",
      "Finished job:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:27<00:41,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  19\n",
      "Finished job:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:30<00:39,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  20\n",
      "Finished job:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:34<00:41,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  21\n",
      "Finished job:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:38<00:41,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  22\n",
      "Finished job:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:42<00:39,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  23\n",
      "Finished job:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:46<00:37,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  24\n",
      "Finished job:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:50<00:34,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  25\n",
      "Finished job:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:55<00:33,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  26\n",
      "Finished job:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:00<00:31,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  27\n",
      "Finished job:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:05<00:27,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  28\n",
      "Finished job:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [01:10<00:23,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling qa pair:  29\n",
      "Finished job:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [01:15<00:19,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job:  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [01:21<00:15,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job:  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [01:27<00:10,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [01:33<00:05,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job:  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:39<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ele = {\"qid\": 0, \"question\": \"q\", \"answer\": \"a\"}\n",
    "\n",
    "def handle_qa_pair(index, question, model_name, prompt, q):\n",
    "    print(\"Handling qa pair: \", index)\n",
    "    try:\n",
    "        # if index % 50 == 0 and index != 0:\n",
    "        #     print(\"************\", index)\n",
    "        #     time.sleep(10)\n",
    "        response = make_completion_request(model_name, prompt, question, index)\n",
    "\n",
    "        # if response.choices[0].text.strip() == \"\":\n",
    "        #     answer = \"<no response>\"\n",
    "        # else:\n",
    "        #     answer = response.choices[0].text.strip()\n",
    "        answer = response\n",
    "    except Exception as e:\n",
    "        print(\"Could not get response. Here is the exception:\", str(e))\n",
    "        answer = \"<exception>\"\n",
    "\n",
    "    # Put response into queue\n",
    "    q.put({\"qid\": index, \"question\": question, \"answer\": answer})\n",
    "    print(\"Finished job: \", index)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "# def worker_function(item, q):\n",
    "#     \"\"\"\n",
    "#     do some work, put results in queue\n",
    "#     \"\"\"\n",
    "#     res = f'item: {item} - result: {item ** 2}'\n",
    "#     print(res)\n",
    "#     q.put(res)\n",
    "\n",
    "\n",
    "def listener(q):\n",
    "    \"\"\"\n",
    "    continue to listen for messages on the queue and writes to file when receive one\n",
    "    if it receives a '#done#' message it will exit\n",
    "    \"\"\"\n",
    "    with open('output_new.txt', 'wb') as f:\n",
    "        while True:\n",
    "            m = q.get()\n",
    "            print(\"Heres the message: \", m)\n",
    "            if m == '#done#':\n",
    "                print(\"Got break\")\n",
    "                break\n",
    "            f.write(f\"{m['qid']}\\t{m['question']}\\t{m['anwser']}\\n\")\n",
    "            print(\"Wrote line to file\")\n",
    "            f.flush()\n",
    "\n",
    "\n",
    "manager = mp.Manager()\n",
    "q = manager.Queue()\n",
    "file_pool = mp.Pool(1)\n",
    "file_pool.apply_async(listener, (q, ))\n",
    "\n",
    "pool = mp.Pool(5)\n",
    "jobs = []\n",
    "\n",
    "data = load_dataset(\"/home/wallat/temporal-llms/data/Event-focused Questions/Explicitly Time-Scoped Questions.csv\")\n",
    "# print(data.head())\n",
    "\n",
    "for index, row in data[:30].iterrows():\n",
    "    question = row[\"Question\"]\n",
    "    job = pool.apply_async(handle_qa_pair, (index, question, \"<model_name>\", \"<prompt>\", q))\n",
    "    jobs.append(job)\n",
    "\n",
    "for job in tqdm(jobs):\n",
    "    job.get()\n",
    "\n",
    "q.put('#done#')  # all workers are done, we close the output file\n",
    "pool.close()\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
